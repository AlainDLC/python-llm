{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import Audio, display,Markdown, display, update_display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f72c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "if openai_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ecb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8053baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "system_message=\"You are a expert in technical question please responds with an explanation\"\n",
    "system_message += \"Give short, courteous answers, no more than 5 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages= [{\n",
    "        \"role\":\"system\",\"content\" : system_message\n",
    "    },{\n",
    "        \"role\":\"user\",\"content\": prompt\n",
    "    }]\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2267f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def message_ollama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "        # kolla att 'delta' finns\n",
    "        delta = getattr(chunk.choices[0], \"delta\", None)\n",
    "        if delta and hasattr(delta, \"content\"):\n",
    "            result += delta.content\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2697a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model(prompt,model):\n",
    "    if model ==\"OpenAi\":\n",
    "        result = message_gpt(prompt)\n",
    "    elif model == \"Ollama\":\n",
    "        result = message_ollama(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Uknow model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=change_model,\n",
    "             inputs=[gr.Textbox(label=\"Your massage\"), gr.Dropdown([\"OpenAi\", \"Ollama\"], label=\"Select model\" , value=\"OpenAi\")],\n",
    "             outputs=[gr.Markdown(label=\"Response: \")] ,\n",
    "             flagging_mode=\"never\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcff512",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELGPT = \"gpt-4o-mini\"\n",
    "\n",
    "programing_level= {\"python\":\"easy\",\"javascript\":\"easy\",\"C\":\"hard\",\"C#\":\"intermediate\"}\n",
    "\n",
    "def get_level(programming):\n",
    "     print(f\"Tool get_level called for {programming}\")\n",
    "     if not programming:  # Kollar om booking är None eller tom sträng\n",
    "        return \"No booking info provided\"\n",
    "     level = programming.lower()\n",
    "     return programing_level.get(level,\"Unknown\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_function = {\n",
    "    \"name\": \"get_level\",\n",
    "    \"description\": \"Get the level of a programming language for technical question . Call this whenever you need to know the level programming, for example when a customer asks 'How hard is a programming Python'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The programing_level that the customer wants to know \",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"programming\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": level_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    level = arguments.get('programming')\n",
    "\n",
    "    if not level:   # Hantera None eller tom sträng\n",
    "        level = \"\"\n",
    "    programming = get_level(level)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"programming\": level,\"programming\": programming}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"sage\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dfdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODELGPT, messages=messages, tools=tools)\n",
    "    \n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODELGPT, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "   \n",
    "    talker(reply)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce44a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with your Ai Assistans:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
